BiRNN Sentiment Analysis

Overview ğŸ“–

This project implements a Bidirectional Recurrent Neural Network (BiRNN) for sentiment analysis, using pretrained word embeddings (GloVe) and LSTM layers for feature extraction. It predicts whether a given text has a positive or negative sentiment, making it ideal for analyzing customer feedback, reviews, and opinions.

Features âœ¨

BiRNN with LSTM: Captures sequential word dependencies in text.

GloVe Embeddings: Uses pre-trained word vectors for better generalization.

Tokenization & Vocabulary Generation: Converts raw text into a structured format.

Learning Curve Analysis: Tracks training performance over time.

Early Stopping: Prevents overfitting by monitoring validation loss.

Evaluation Metrics: Computes accuracy, precision, recall, and F1-score.

Project Structure ğŸ—ï¸

â”œâ”€â”€ BiRNN/

â”‚   â”œâ”€â”€ train.py                 # Trains the BiRNN model with early stopping

â”‚   â”œâ”€â”€ evaluate.py              # Evaluates the trained model on test data

â”‚   â”œâ”€â”€ StackedBiNN.py           # Defines the BiRNN architecture

â”‚   â”œâ”€â”€ utils.py                 # Data preprocessing, tokenization & embeddings

â”‚   â”œâ”€â”€ dataset_loader.py        # Loads dataset into PyTorch DataLoader

â”‚   â”œâ”€â”€ best_model.pth           # Saved best performing model

â”‚   â”œâ”€â”€ add glove 300d embedings here ####

â”œâ”€â”€ Dataset/

â”‚   â”œâ”€â”€ aclImdb/                 # IMDB movie review dataset

â”œâ”€â”€ README.md                    # This documentation

How It Works ğŸš€

1ï¸âƒ£ Dataset Loading

Loads IMDB dataset with positive and negative movie reviews.

Tokenizes text and converts it into numerical sequences.

Splits data into training, validation, and test sets.

2ï¸âƒ£ Model Training

Uses a Stacked BiRNN (Bi-LSTM) architecture.

Initializes with GloVe embeddings for better word representations.

Employs Adam optimizer and cross-entropy loss.

Early stopping prevents overfitting by tracking validation loss.

Saves the best model checkpoint based on development loss.

3ï¸âƒ£ Evaluation & Prediction

Tests the model on unseen IMDB reviews.

Computes accuracy, precision, recall, and F1-score.

Predicts the sentiment of new text samples.


Usage ğŸ› ï¸

1ï¸âƒ£ Train the Model

python BiRNN/train.py

This will train the model and save the best version as best_model.pth.

2ï¸âƒ£ Evaluate the Model

python BiRNN/evaluate.py

This script loads the trained model and evaluates its accuracy and performance metrics on the test set.

3ï¸âƒ£ Predict Sentiment for New Text

Modify evaluate.py to provide a custom text input for prediction.

Learning Curve ğŸ“ˆ

During training, we track the loss on both training and validation data. The loss curves help us understand the modelâ€™s generalization ability. The training script automatically smooths the learning curve using interpolation for better visualization.
